{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset,Subset, random_split\n",
    "import torchvision\n",
    "from torchvision import datasets, models\n",
    "from torchvision import transforms as T\n",
    "import torchvision.transforms.functional as F\n",
    "import torch.nn as nn\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import lightning as L\n",
    "from lightning.pytorch import loggers as pl_loggers\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "import torchmetrics, argparse\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "import multiprocessing\n",
    "num_workers = multiprocessing.cpu_count()\n",
    "print(num_workers)\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    ver = 4.1\n",
    "    seed = 42\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    base_dir =  \"/root/signate_tecno/\"\n",
    "    base_input_dir = base_dir + \"input\"\n",
    "    input_dir = base_dir + \"input/train\"\n",
    "    test_dir = base_dir + \"input/test\"\n",
    "    output_dir = base_dir + \"output/\"\n",
    "    sub_dir  = base_dir + \"submit/\"\n",
    "    log_dir = base_dir + \"logs/\"\n",
    "    model_dir = base_dir + \"model/\"\n",
    "    ckpt_dir = base_dir + \"ckpt/\"\n",
    "\n",
    "    MODEL = \"vit-tiny\"\n",
    "    DATASET = \"TECNO\"\n",
    "\n",
    "\n",
    "    learning_rate = 1e-3\n",
    "    weight_decay = 1e-5\n",
    "    optimizer = \"SGD\"\n",
    "    data_aug = \"RandAug\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViTNet(L.LightningModule):\n",
    "    def __init__(self,learning_rate = 1e-3, weight_decay = 1e-5, optimizer_name = \"SGD\", data_aug = \"RandAug\"):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(\"vit_tiny_patch16_384\" , pretrained = True, num_classes = 2)\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        self.optimizer_name = optimizer_name\n",
    "        self.data_aug = data_aug\n",
    "        self.save_hyperparameters()\n",
    "        self.acc = torchmetrics.classification.Accuracy(task= 'binary')\n",
    "        self.class_acc = torchmetrics.classification.Accuracy(task = 'binary')\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.predictions = []\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = self.model(x)\n",
    "        return out\n",
    "\n",
    "    def _eval(self,batch,phase, on_step , on_epoch):\n",
    "        x,y = batch\n",
    "        out = self(x)\n",
    "        loss = self.loss_fn(out, y)\n",
    "        preds = torch.argmax(out, dim=1)\n",
    "        acc = self.acc(preds, y)\n",
    "        self.log(f\"{phase}_loss\", loss)\n",
    "        self.log(f\"{phase}_acc\", acc, on_step = on_step, on_epoch = on_epoch)\n",
    "        if phase == \"val\":\n",
    "            self.class_acc(preds,y)\n",
    "            self.log('hp_metric', acc, on_step = False, on_epoch = True,prog_bar = True, logger = True)\n",
    "        return loss\n",
    "\n",
    "    def training_step ( self,batch, batch_idx):\n",
    "        loss = self._eval(batch, \"train\", on_step = False, on_epoch = True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss = self._eval(batch, \"val\", on_step = False, on_epoch = True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x = batch\n",
    "        out = self(x)\n",
    "        self.predictions.append(out)\n",
    "        return out\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        all_preds = torch.cat(self.predictions, dim=0)\n",
    "        probs = torch.softmax(all_preds, dim=1)[:, 1]  # クラス1の確率を取得\n",
    "        self.predictions.clear()  # 保存された出力をクリア\n",
    "\n",
    "        return probs.cpu().numpy()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        if self.optimizer_name == \"SGD\":\n",
    "            optimizer = optim.SGD(self.parameters(), lr = self.learning_rate, weight_decay = self.weight_decay)\n",
    "        elif self.optimizer_name == \"Adam\":\n",
    "            optimizer = optim.Adam(self.parameters(), lr = self.learning_rate, weight_decay = self.weight_decay)\n",
    "        elif self.optimizer_name == \"AdamW\":\n",
    "            optimizer = optim.AdamW(self.parameters(), lr = self.learning_rate, weight_decay = self.weight_decay)\n",
    "\n",
    "        return optimizer\n",
    "\n",
    "net = ViTNet(learning_rate = CFG.learning_rate,\n",
    "             weight_decay = CFG.weight_decay,\n",
    "             optimizer_name = CFG.optimizer,\n",
    "             data_aug = CFG.data_aug)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sample_submit = pd.read_csv(CFG.base_input_dir + \"/sample_submit.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDatset(Dataset):\n",
    "    def __init__(self,df,data_dir,transform=None):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.image_paths = df[0]\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, index):\n",
    "        image_path = CFG.test_dir +\"/\"+self.image_paths[index]\n",
    "        image = Image.open(image_path)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataModule(L.LightningDataModule):\n",
    "    def __init__(self,df,batch_size = 32, data_dir = \"./input\", ds = None):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.test_transform = T.Compose([\n",
    "                                        T.Resize((384,384)),\n",
    "                                        T.ToTensor(),\n",
    "                                        T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ])\n",
    "    def setup(self,stage = None):\n",
    "        if stage == \"test\" or stage is None:\n",
    "            self.test_dataset = TestDatset(self.df,self.data_dir,self.test_transform)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size, num_workers = num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dm = TestDataModule(df = sample_submit,data_dir = CFG.test_dir)\n",
    "test_dm.prepare_data()\n",
    "test_dm.setup(stage = \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = CFG.ckpt_dir + f\"TECNO-{CFG.ver}-{CFG.MODEL}-fold1.ckpt\"\n",
    "net = ViTNet.load_from_checkpoint(checkpoint_path)\n",
    "net.eval()\n",
    "net.freeze()\n",
    "\n",
    "\n",
    "predict_list, targets_list = [], []\n",
    "\n",
    "for process, images in enumerate(test_dm.test_dataloader()):\n",
    "    images = images.to(CFG.device)\n",
    "    with torch.no_grad():\n",
    "        outputs = net(images)\n",
    "        predicts = outputs.softmax(dim = 1)\n",
    "    predicts = predicts.cpu().detach().numpy()\n",
    "    predict_list.append(predicts)\n",
    "\n",
    "predict_list = np.concatenate(predict_list,axis = 0)\n",
    "\n",
    "predict_list = predict_list[:,1]\n",
    "# prompt: predict_listを元に0,1に2値変換してください\n",
    "\n",
    "predicted_labels = (predict_list > 0.5).astype(int)\n",
    "\n",
    "sample_submit[1] = predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "predict_list = np.zeros(len(sample_submit))\n",
    "\n",
    "for fold in range(n_folds):\n",
    "    checkpoint_path = CFG.ckpt_dir + f\"TECNO-{CFG.ver}-{CFG.MODEL}-fold{fold}.ckpt\"\n",
    "    net = ViTNet.load_from_checkpoint(checkpoint_path)\n",
    "    net.eval()\n",
    "    net.freeze()\n",
    "\n",
    "    fold_predict_list = []\n",
    "    test_dm = TestDataModule(df = sample_submit,data_dir = CFG.test_dir)\n",
    "    test_dm.prepare_data()\n",
    "    test_dm.setup(stage = \"test\")\n",
    "\n",
    "    for process, images in enumerate(test_dm.test_dataloader()):\n",
    "        images = images.to(CFG.device)\n",
    "        with torch.no_grad():\n",
    "            outputs = net(images)\n",
    "            predicts = outputs.softmax(dim=1)\n",
    "        predicts = predicts.cpu().detach().numpy()\n",
    "        fold_predict_list.append(predicts)\n",
    "\n",
    "    fold_predict_list = np.concatenate(fold_predict_list, axis=0)\n",
    "    fold_predict_list = fold_predict_list[:, 1]\n",
    "    predict_list += fold_predict_list\n",
    "\n",
    "predict_list /= n_folds\n",
    "\n",
    "predicted_labels = (predict_list > 0.5).astype(int)\n",
    "sample_submit[1] = predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submit[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submit[1] = predicted_labels\n",
    "sample_submit.to_csv(f\"{CFG.sub_dir}/{CFG.ver}-{CFG.MODEL}-{CFG.seed}.csv\", index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
