{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "\n",
    "#必要なライブラリのインポート\n",
    "import re, gc, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "\n",
    "import warnings, random\n",
    "import cv2\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "from torch.cuda.amp import GradScaler\n",
    "\n",
    "import timm\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import copy\n",
    "from collections import defaultdict\n",
    "\n",
    "from colorama import Fore, Back, Style\n",
    "b_ = Fore.BLUE\n",
    "y_ = Fore.YELLOW\n",
    "sr_ = Style.RESET_ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARGS = {\n",
    "  'DATA_DIR': '/root/signate_tecno/input/',\n",
    "  'OUT_DIR': '/root/signate_tecno/output',\n",
    "  'model_name': 'vit_l_16',\n",
    "  'image_size': (224, 224), # vit_l16\n",
    "  #cpu(slow)\n",
    "  #'train_batch_size': 4,\n",
    "  #'test_batch_size': 8,\n",
    "  #gpu\n",
    "  #'train_batch_size': 28, # 32(x)\n",
    "  #'test_batch_size': 56,\n",
    "  #'n_fold': 2,\n",
    "  #'epochs': 3,\n",
    "  #'timm_model_name': 'resnet50',\n",
    "  #'timm_model_name': 'vit_base_patch16_224',\n",
    "  #lb:0.8545424 ? :\n",
    "  #'timm_model_name': 'vit_large_patch32_224_in21k',\n",
    "  #down?\n",
    "  #'timm_model_name': 'vit_huge_patch14_224_in21k',\n",
    "  #colab free crash memory?.(batch=4)\n",
    "  #'timm_model_name': 'vit_giant_patch14_224_clip_laion2b',\n",
    "  #Only one class present in y_true. ROC AUC score is not defined in that case.\n",
    "  #lb:0.8944379  : top, batchsize : 4, 'image_size': (448, 448),\n",
    "  #'timm_model_name': 'eva02_large_patch14_448.mim_m38m_ft_in22k_in1k',\n",
    "  'timm_model_name': \"timm/vit_mediumd_patch16_reg4_gap_384.sbb2_e200_in12k_ft_in1k\"\n",
    "  'pretrained': True,\n",
    "  'n_fold': 2, # 5\n",
    "  'epochs': 2, # 8\n",
    "  'image_size': (384, 384), # eva02_large_patch14_448\n",
    "  'criterion': 'CrossEntropy',\n",
    "  #'is_blurry': True,\n",
    "  'is_blurry': False,\n",
    "  #'image_size': (336, 336),\n",
    "  #GPU: 16GB\n",
    "  'train_batch_size': 5, # 4, #1(ng?)\n",
    "  'test_batch_size': 15, #x3?\n",
    "  #GPU: 80GB?\n",
    "  #'train_batch_size': 32, # 4, #1(ng?)\n",
    "  #'test_batch_size': 96,\n",
    "  #batchsize row is roc_auc calc ng,(batchsizeが小さいと、class data が片方のみ存在している状態になり roc_auc の計算ができない)\n",
    "  'seed': 2023,\n",
    "  'optimizer': 'AdamW',\n",
    "  'learning_rate': 1e-05,\n",
    "  'scheduler': 'CosineAnnealingLR', # CosineAnnealingWarmRestarts\n",
    "  'min_lr': 1e-06,\n",
    "  'T_max': 500,\n",
    "  'n_accumulate': 1,\n",
    "  'clip_grad_norm': 'None',\n",
    "  'apex': True,\n",
    "  'num_classes': 2,\n",
    "  'device': torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folds(data, num_splits, seed):\n",
    "    data[\"kfold\"] = -1\n",
    "\n",
    "    mskf = StratifiedKFold(n_splits=num_splits, shuffle=True, random_state=seed)\n",
    "    labels = [\"label\"]\n",
    "    data_labels = data[labels].values\n",
    "\n",
    "    for f, (t_, v_) in enumerate(mskf.split(data, data_labels)):\n",
    "        data.loc[v_, \"kfold\"] = f\n",
    "\n",
    "    return data\n",
    "\n",
    "train = pd.read_csv(f\"{ARGS['DATA_DIR']}/train.csv\")\n",
    "train = create_folds(train, num_splits=ARGS[\"n_fold\"], seed=ARGS[\"seed\"])\n",
    "print(\"Folds created successfully\")\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as albu\n",
    "from albumentations.pytorch import transforms as AT\n",
    "\n",
    "# Augumentation用\n",
    "#CV : up, LB : down\n",
    "image_transform_train = albu.Compose([\n",
    "    albu.Resize(ARGS[\"image_size\"][0], ARGS[\"image_size\"][1]),\n",
    "    albu.HorizontalFlip(p=0.5),\n",
    "    albu.VerticalFlip(p=0.5),\n",
    "    albu.RandomBrightnessContrast(p=0.3),\n",
    "    albu.RandomGamma(gamma_limit=(85, 115), p=0.3),\n",
    "    albu.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.10, rotate_limit=45, p=0.5),\n",
    "    albu.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    AT.ToTensorV2()\n",
    "])\n",
    "\n",
    "image_transform = albu.Compose([\n",
    "    albu.Resize(ARGS[\"image_size\"][0], ARGS[\"image_size\"][1]),\n",
    "    # albu.HorizontalFlip(p=0.5),\n",
    "    # albu.VerticalFlip(p=0.5),\n",
    "    # albu.RandomBrightnessContrast(p=0.3),\n",
    "    # albu.RandomGamma(gamma_limit=(85, 115), p=0.3),\n",
    "    # albu.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.10, rotate_limit=45, p=0.5),\n",
    "    albu.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    AT.ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
